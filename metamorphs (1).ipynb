{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":103669,"databundleVersionId":12900657,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n# +\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T15:17:43.269485Z","iopub.execute_input":"2025-07-06T15:17:43.270144Z","iopub.status.idle":"2025-07-06T15:17:43.276954Z","shell.execute_reply.started":"2025-07-06T15:17:43.270117Z","shell.execute_reply":"2025-07-06T15:17:43.275499Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Lung Cancer Detection**","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T16:53:39.061244Z","iopub.execute_input":"2025-07-06T16:53:39.061566Z","iopub.status.idle":"2025-07-06T16:53:39.066346Z","shell.execute_reply.started":"2025-07-06T16:53:39.061544Z","shell.execute_reply":"2025-07-06T16:53:39.065353Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loading the Dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/idealize-2025-datathon-competition/train.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T16:53:39.309983Z","iopub.execute_input":"2025-07-06T16:53:39.310346Z","iopub.status.idle":"2025-07-06T16:53:43.404289Z","shell.execute_reply.started":"2025-07-06T16:53:39.310319Z","shell.execute_reply":"2025-07-06T16:53:43.403173Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df.drop(['first_name', 'last_name', 'record_id'], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T16:53:43.405965Z","iopub.execute_input":"2025-07-06T16:53:43.406354Z","iopub.status.idle":"2025-07-06T16:53:43.596571Z","shell.execute_reply.started":"2025-07-06T16:53:43.406323Z","shell.execute_reply":"2025-07-06T16:53:43.595377Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T16:53:43.597705Z","iopub.execute_input":"2025-07-06T16:53:43.598063Z","iopub.status.idle":"2025-07-06T16:53:43.617651Z","shell.execute_reply.started":"2025-07-06T16:53:43.598040Z","shell.execute_reply":"2025-07-06T16:53:43.616562Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data exploration","metadata":{}},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T16:53:43.620101Z","iopub.execute_input":"2025-07-06T16:53:43.620390Z","iopub.status.idle":"2025-07-06T16:53:44.258078Z","shell.execute_reply.started":"2025-07-06T16:53:43.620370Z","shell.execute_reply":"2025-07-06T16:53:44.256904Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Pre-processing\n### Data preprocessing Steps\n- Filling `cigarattes_per_day` \n- Columns to encode(Binary) : `family_cancer_history`, `has_other_cancer`, `asthma_diagnosis`, `liver_condition`, `blood_pressure_status`\n- Columns to encode (OneHot) : `residence_state`, `smoking_status`, `treatment_type`","metadata":{"execution":{"iopub.status.busy":"2025-07-04T13:43:06.471176Z","iopub.execute_input":"2025-07-04T13:43:06.471498Z","iopub.status.idle":"2025-07-04T13:43:06.484624Z","shell.execute_reply.started":"2025-07-04T13:43:06.471453Z","shell.execute_reply":"2025-07-04T13:43:06.483557Z"}}},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\n\nclass ProcessSmoking(BaseEstimator,TransformerMixin):\n    def fit(self,X,y=None):\n        return self\n\n    def transform(self,X):\n        X.loc[df['smoking_status'] == 'Never Smoked', 'cigarettes_per_day'] = 0\n        X.loc[df['smoking_status'] == 'Passive Smoker', 'cigarettes_per_day'] = 0\n        X.loc[df['smoking_status'] == 'Passive', 'cigarettes_per_day'] = 0\n        X.loc[df['smoking_status'] == 'Non Smoker', 'cigarettes_per_day'] = 0\n        return X\n    \n\nclass ProcessCols(BaseEstimator,TransformerMixin):\n    def fit(self,X,y=None):\n        return self\n\n    def transform(self,X):\n        # Encode 'family_cancer_history': Yes → 1, No → 0\n        X['family_cancer_history'] = X['family_cancer_history'].replace({'Yes': 1, 'No': 0})\n        \n        # Encode 'has_other_cancer': Yes → 1, No → 0\n        X['has_other_cancer'] = X['has_other_cancer'].replace({'Yes': 1, 'No': 0})\n        \n        # Encode 'asthma_diagnosis': Yes → 1, No → 0\n        X['asthma_diagnosis'] = X['asthma_diagnosis'].replace({'Yes': 1, 'No': 0})\n        \n        # Clean and encode 'blood_pressure_status'\n        X['blood_pressure_status'] = X['blood_pressure_status'].replace({\n            'High Blood Pressure': 1,\n            'Elevated': 1,\n            'Normal': 0,\n            'Normal BP': 0  # Treating 'Normal' and 'Normal BP' as same\n        })\n        \n        # Clean and encode 'liver_condition'\n        X['liver_condition'] = X['liver_condition'].replace({\n            'Normal': 0,\n            'Normal Liver': 0,\n            'Liver OK': 0,\n            'No Issue': 0,\n            'Has Cirrhosis': 1,\n            'Cirrhos': 1  # Assuming typo or shorthand for cirrhosis\n        })\n        X['sex'] = X['sex'].replace({'Male': 1, 'Female': 0})\n        X['smoking_status'] = X['smoking_status'].replace({\n            'Current Smoker': 'Current',\n            'Former Smoker': 'Former',\n            'Passive Smoker': 'Passive',\n            'Never Smoked': 'Never',\n            'Passive': 'Passive',\n            'Non Smoker': 'Never',\n            'Former Smk': 'Former'\n        })\n        X['treatment_type'] = X['treatment_type'].replace({\n            'Chemo': 'Chemotherapy',\n            'Surg': 'Surgery',\n            'Combo': 'Combined'\n        })\n        X = X.drop('residence_state', axis=1)\n        \n        return X\n\nclass EncodeCatCols(BaseEstimator, TransformerMixin):\n    def __init__(self, columns=None):\n        self.columns = columns\n        self.encoder = OneHotEncoder(handle_unknown='ignore')\n\n    def fit(self, X, y=None):\n        self.encoder.fit(X[self.columns])\n        return self\n\n    def transform(self, X):\n        encoded = self.encoder.transform(X[self.columns])\n        encoded_df = pd.DataFrame(\n            encoded, \n            columns=self.encoder.get_feature_names_out(self.columns),\n            index=X.index  # preserve index\n        )\n        X = X.drop(columns=self.columns)\n        X = pd.concat([X, encoded_df], axis=1)\n        return X\n\n\nclass FormatDates(BaseEstimator,TransformerMixin):\n    def fit(self,X,y=None):\n        return self\n\n    def transform(self,X):\n        X['treatment_start_date'] = pd.to_datetime(X['treatment_start_date'], errors='coerce')\n        X['treatment_end_date'] = pd.to_datetime(X['treatment_end_date'], errors='coerce')\n        X['diagnosis_date'] = pd.to_datetime(X['diagnosis_date'], errors='coerce')\n        X['treatment_duration'] = (X['treatment_end_date'] - X['treatment_start_date']).dt.days\n        X['diagnosis_to_treatment_delay'] = (X['treatment_start_date'] - X['diagnosis_date']).dt.days\n        \n        X = X.drop(['treatment_end_date', 'treatment_start_date', 'diagnosis_date'], axis=1)\n        return X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T17:38:35.682723Z","iopub.execute_input":"2025-07-06T17:38:35.683129Z","iopub.status.idle":"2025-07-06T17:38:35.700490Z","shell.execute_reply.started":"2025-07-06T17:38:35.683106Z","shell.execute_reply":"2025-07-06T17:38:35.699471Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Filling `cigarattes_per_day`","metadata":{}},{"cell_type":"code","source":"# Current Smokers - no NaNs\n# Never Smoked - no NaNs\n# Former Smokers - no NaNs\n# Passive smokers - contain NaNs \ndf.loc[df['smoking_status'] == 'Never Smoked', 'cigarettes_per_day'] = 0\ndf.loc[df['smoking_status'] == 'Passive Smoker', 'cigarettes_per_day'] = 0\ndf.loc[df['smoking_status'] == 'Passive', 'cigarettes_per_day'] = 0\ndf.loc[df['smoking_status'] == 'Non Smoker', 'cigarettes_per_day'] = 0\n\n\ndf.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T16:53:44.444344Z","iopub.execute_input":"2025-07-06T16:53:44.444678Z","iopub.status.idle":"2025-07-06T16:53:45.421711Z","shell.execute_reply.started":"2025-07-06T16:53:44.444647Z","shell.execute_reply":"2025-07-06T16:53:45.420852Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['cigarettes_per_day'].isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T16:53:45.422818Z","iopub.execute_input":"2025-07-06T16:53:45.423088Z","iopub.status.idle":"2025-07-06T16:53:45.434054Z","shell.execute_reply.started":"2025-07-06T16:53:45.423068Z","shell.execute_reply":"2025-07-06T16:53:45.433104Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Encoding Binary Columns \n\n`family_cancer_history`, `has_other_cancer`, `asthma_diagnosis`, `liver_condition`, `blood_pressure_status`, `sex`","metadata":{}},{"cell_type":"code","source":"df['smoking_status'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T16:53:45.435189Z","iopub.execute_input":"2025-07-06T16:53:45.435517Z","iopub.status.idle":"2025-07-06T16:53:45.526687Z","shell.execute_reply.started":"2025-07-06T16:53:45.435495Z","shell.execute_reply":"2025-07-06T16:53:45.525734Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Encode 'family_cancer_history': Yes → 1, No → 0\ndf['family_cancer_history'] = df['family_cancer_history'].replace({'Yes': 1, 'No': 0})\n\n# Encode 'has_other_cancer': Yes → 1, No → 0\ndf['has_other_cancer'] = df['has_other_cancer'].replace({'Yes': 1, 'No': 0})\n\n# Encode 'asthma_diagnosis': Yes → 1, No → 0\ndf['asthma_diagnosis'] = df['asthma_diagnosis'].replace({'Yes': 1, 'No': 0})\n\n# Clean and encode 'blood_pressure_status'\ndf['blood_pressure_status'] = df['blood_pressure_status'].replace({\n    'High Blood Pressure': 1,\n    'Elevated': 1,\n    'Normal': 0,\n    'Normal BP': 0  # Treating 'Normal' and 'Normal BP' as same\n})\n\n# Clean and encode 'liver_condition'\ndf['liver_condition'] = df['liver_condition'].replace({\n    'Normal': 0,\n    'Normal Liver': 0,\n    'Liver OK': 0,\n    'No Issue': 0,\n    'Has Cirrhosis': 1,\n    'Cirrhos': 1  # Assuming typo or shorthand for cirrhosis\n})\n\ndf['sex'] = df['sex'].replace({'Male': 1, 'Female': 0})\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T16:53:45.527829Z","iopub.execute_input":"2025-07-06T16:53:45.528140Z","iopub.status.idle":"2025-07-06T16:53:48.006409Z","shell.execute_reply.started":"2025-07-06T16:53:45.528118Z","shell.execute_reply":"2025-07-06T16:53:48.005237Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T16:53:48.009652Z","iopub.execute_input":"2025-07-06T16:53:48.009956Z","iopub.status.idle":"2025-07-06T16:53:48.028289Z","shell.execute_reply.started":"2025-07-06T16:53:48.009933Z","shell.execute_reply":"2025-07-06T16:53:48.027024Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Encoding multi-class columns \n- `residence_state`, `smoking_status`, `treatment_type`","metadata":{}},{"cell_type":"code","source":"df['smoking_status'] = df['smoking_status'].replace({\n    'Current Smoker': 'Current',\n    'Former Smoker': 'Former',\n    'Passive Smoker': 'Passive',\n    'Never Smoked': 'Never',\n    'Passive': 'Passive',\n    'Non Smoker': 'Never',\n    'Former Smk': 'Former'\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T16:53:48.029601Z","iopub.execute_input":"2025-07-06T16:53:48.029983Z","iopub.status.idle":"2025-07-06T16:53:48.426608Z","shell.execute_reply.started":"2025-07-06T16:53:48.029951Z","shell.execute_reply":"2025-07-06T16:53:48.425527Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['treatment_type'] = df['treatment_type'].replace({\n    'Chemo': 'Chemotherapy',\n    'Surg': 'Surgery',\n    'Combo': 'Combined'\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T16:53:48.427593Z","iopub.execute_input":"2025-07-06T16:53:48.427873Z","iopub.status.idle":"2025-07-06T16:53:48.596492Z","shell.execute_reply.started":"2025-07-06T16:53:48.427853Z","shell.execute_reply":"2025-07-06T16:53:48.595604Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['treatment_type'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T16:53:48.597646Z","iopub.execute_input":"2025-07-06T16:53:48.597965Z","iopub.status.idle":"2025-07-06T16:53:48.678831Z","shell.execute_reply.started":"2025-07-06T16:53:48.597939Z","shell.execute_reply":"2025-07-06T16:53:48.677780Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T16:53:48.679675Z","iopub.execute_input":"2025-07-06T16:53:48.679958Z","iopub.status.idle":"2025-07-06T16:53:48.702861Z","shell.execute_reply.started":"2025-07-06T16:53:48.679936Z","shell.execute_reply":"2025-07-06T16:53:48.701749Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import OneHotEncoder\nimport pandas as pd\n\n\nclass EncodeCatCols(BaseEstimator, TransformerMixin):\n    def __init__(self, columns=None):\n        self.columns = columns\n        self.encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n\n    def fit(self, X, y=None):\n        self.encoder.fit(X[self.columns])\n        return self\n\n    def transform(self, X):\n        encoded = self.encoder.transform(X[self.columns])\n        encoded_df = pd.DataFrame(\n            encoded, \n            columns=self.encoder.get_feature_names_out(self.columns),\n            index=X.index  # preserve index\n        )\n        X = X.drop(columns=self.columns)\n        X = pd.concat([X, encoded_df], axis=1)\n        return X\n\ncat_cols = ['smoking_status', 'treatment_type']\nencoder = EncodeCatCols(columns=cat_cols)\n\ndf = encoder.fit_transform(df)\n\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T16:53:48.706108Z","iopub.execute_input":"2025-07-06T16:53:48.706472Z","iopub.status.idle":"2025-07-06T16:53:49.930954Z","shell.execute_reply.started":"2025-07-06T16:53:48.706447Z","shell.execute_reply":"2025-07-06T16:53:49.929971Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T16:53:49.931777Z","iopub.execute_input":"2025-07-06T16:53:49.931999Z","iopub.status.idle":"2025-07-06T16:53:49.940107Z","shell.execute_reply.started":"2025-07-06T16:53:49.931982Z","shell.execute_reply":"2025-07-06T16:53:49.938755Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df.drop('residence_state', axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T16:53:49.941154Z","iopub.execute_input":"2025-07-06T16:53:49.941449Z","iopub.status.idle":"2025-07-06T16:53:50.021959Z","shell.execute_reply.started":"2025-07-06T16:53:49.941421Z","shell.execute_reply":"2025-07-06T16:53:50.020527Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T16:53:50.022931Z","iopub.execute_input":"2025-07-06T16:53:50.023197Z","iopub.status.idle":"2025-07-06T16:53:50.031657Z","shell.execute_reply.started":"2025-07-06T16:53:50.023177Z","shell.execute_reply":"2025-07-06T16:53:50.030350Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['treatment_start_date'] = pd.to_datetime(df['treatment_start_date'], errors='coerce')\ndf['treatment_end_date'] = pd.to_datetime(df['treatment_end_date'], errors='coerce')\ndf['diagnosis_date'] = pd.to_datetime(df['diagnosis_date'], errors='coerce')\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T16:53:50.034575Z","iopub.execute_input":"2025-07-06T16:53:50.035258Z","iopub.status.idle":"2025-07-06T16:53:50.716605Z","shell.execute_reply.started":"2025-07-06T16:53:50.035229Z","shell.execute_reply":"2025-07-06T16:53:50.715430Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T16:53:50.717564Z","iopub.execute_input":"2025-07-06T16:53:50.717999Z","iopub.status.idle":"2025-07-06T16:53:50.726398Z","shell.execute_reply.started":"2025-07-06T16:53:50.717974Z","shell.execute_reply":"2025-07-06T16:53:50.725062Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['treatment_duration'] = (df['treatment_end_date'] - df['treatment_start_date']).dt.days\ndf['diagnosis_to_treatment_delay'] = (df['treatment_start_date'] - df['diagnosis_date']).dt.days\n\ndf = df.drop(['treatment_end_date', 'treatment_start_date', 'diagnosis_date'], axis=1)\ndf.dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T16:53:50.727451Z","iopub.execute_input":"2025-07-06T16:53:50.727749Z","iopub.status.idle":"2025-07-06T16:53:50.885346Z","shell.execute_reply.started":"2025-07-06T16:53:50.727724Z","shell.execute_reply":"2025-07-06T16:53:50.884415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T16:54:01.341883Z","iopub.execute_input":"2025-07-06T16:54:01.342180Z","iopub.status.idle":"2025-07-06T16:54:01.367835Z","shell.execute_reply.started":"2025-07-06T16:54:01.342160Z","shell.execute_reply":"2025-07-06T16:54:01.366501Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = df.drop('survival_status', axis=1)\ny = df['survival_status']\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T16:54:37.661914Z","iopub.execute_input":"2025-07-06T16:54:37.662273Z","iopub.status.idle":"2025-07-06T16:54:37.755539Z","shell.execute_reply.started":"2025-07-06T16:54:37.662250Z","shell.execute_reply":"2025-07-06T16:54:37.754354Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# from sklearn.preprocessing import StandardScaler\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.ensemble import RandomForestClassifier\n# from sklearn.neighbors import KNeighborsClassifier\n# from sklearn.metrics import accuracy_score\n\n# # Split data\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# # Standardize features\n# scaler = StandardScaler()\n# X_train_scaled = scaler.fit_transform(X_train)\n# X_test_scaled = scaler.transform(X_test)\n\n# # Define models\n# models = {\n#     \"Logistic Regression\": LogisticRegression(max_iter=1000),\n#     \"Random Forest\": RandomForestClassifier(),\n#     \"K-Nearest Neighbors\": KNeighborsClassifier()\n# }\n\n# # Train and evaluate\n# for name, model in models.items():\n#     model.fit(X_train_scaled, y_train)\n#     y_pred = model.predict(X_test_scaled)\n#     acc = accuracy_score(y_test, y_pred)\n#     print(f\"{name} Accuracy: {acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T16:56:01.810726Z","iopub.execute_input":"2025-07-06T16:56:01.811212Z","iopub.status.idle":"2025-07-06T17:09:09.212115Z","shell.execute_reply.started":"2025-07-06T16:56:01.811174Z","shell.execute_reply":"2025-07-06T17:09:09.210651Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import tensorflow as tf\n# from tensorflow.keras import layers, models\n# from sklearn.model_selection import train_test_split\n# from sklearn.preprocessing import StandardScaler\n# from sklearn.metrics import accuracy_score\n\n# # 1. Train-test split\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# # 2. Scale features\n# scaler = StandardScaler()\n# X_train = scaler.fit_transform(X_train)\n# X_test = scaler.transform(X_test)\n\n# # 3. Define the neural network\n# model = models.Sequential([\n#     layers.Input(shape=(X_train.shape[1],)),\n#     layers.Dense(128, activation='relu'),\n#     layers.Dense(64, activation='relu'),\n#     layers.Dense(32, activation='relu'),\n#     layers.Dense(1, activation='sigmoid')  # for binary classification\n# ])\n\n# # 4. Compile the model\n# model.compile(optimizer='adam',\n#               loss='binary_crossentropy',\n#               metrics=['accuracy'])\n\n# # 5. Train the model\n# history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.1, verbose=1)\n\n# # 6. Evaluate on test set\n# loss, accuracy = model.evaluate(X_test, y_test)\n# print(f\"\\n✅ Test Accuracy: {accuracy:.4f}\")\n\n# # 7. Predict and show results if needed\n# y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T17:19:18.700201Z","iopub.execute_input":"2025-07-06T17:19:18.700531Z","iopub.status.idle":"2025-07-06T17:24:50.720564Z","shell.execute_reply.started":"2025-07-06T17:19:18.700509Z","shell.execute_reply":"2025-07-06T17:24:50.719113Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test = pd.read_csv(\"/kaggle/input/idealize-2025-datathon-competition/test.csv\")\ndf_test.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T17:26:29.182937Z","iopub.execute_input":"2025-07-06T17:26:29.183252Z","iopub.status.idle":"2025-07-06T17:26:30.485022Z","shell.execute_reply.started":"2025-07-06T17:26:29.183229Z","shell.execute_reply":"2025-07-06T17:26:30.483939Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T17:27:00.674416Z","iopub.execute_input":"2025-07-06T17:27:00.675234Z","iopub.status.idle":"2025-07-06T17:27:00.681734Z","shell.execute_reply.started":"2025-07-06T17:27:00.675205Z","shell.execute_reply":"2025-07-06T17:27:00.680788Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n\n# plt.plot(history.history['accuracy'], label='Training Accuracy')\n# plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n# plt.title('Model Accuracy')\n# plt.xlabel('Epoch')\n# plt.ylabel('Accuracy')\n# plt.legend()\n# plt.grid(True)\n# plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T17:28:21.754608Z","iopub.execute_input":"2025-07-06T17:28:21.755189Z","iopub.status.idle":"2025-07-06T17:28:22.151422Z","shell.execute_reply.started":"2025-07-06T17:28:21.755156Z","shell.execute_reply":"2025-07-06T17:28:22.150444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\ncat_cols = ['smoking_status', 'treatment_type']\n\ndf = pd.read_csv(\"/kaggle/input/idealize-2025-datathon-competition/train.csv\")\n# ✅ Use your existing classes\n# (assume ProcessSmoking, ProcessCols, EncodeCatCols, FormatDates are already defined)\n\n# 📦 Define full pipeline\ndef build_pipeline(cat_columns):\n    return Pipeline([\n        (\"process_smoking\", ProcessSmoking()),\n        (\"process_columns\", ProcessCols()),\n        (\"format_dates\", FormatDates()),\n        (\"encode_categoricals\", EncodeCatCols(columns=cat_cols))\n    ])\n\npipeline = build_pipeline(cat_columns=cat_cols)\npipeline.fit_transform(df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T17:38:44.272970Z","iopub.execute_input":"2025-07-06T17:38:44.273287Z","iopub.status.idle":"2025-07-06T17:38:52.928646Z","shell.execute_reply.started":"2025-07-06T17:38:44.273265Z","shell.execute_reply":"2025-07-06T17:38:52.927647Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}